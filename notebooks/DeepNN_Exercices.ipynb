{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from Complete.utility import print_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "In this session you will be using deep learning to improve the results for image digit recognition problem. You will:\n",
    "- Build a Convolutional Neural Network (CNN).\n",
    "- Train and test your CNN.\n",
    "- Modify the CNN architecture to obtain better results.\n",
    "\n",
    "\n",
    "# Load the data.\n",
    "To load MNIST data from TensorFlow you will need to load the data in a MNIST dataset and give a sample of the content. To do this, follow these steps:\n",
    "\n",
    "__1. Paste and execute in a code cell the following command to ensure the dataset is accessible locally:.__\n",
    "```python\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./Data/MNIST_data', one_hot=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./Data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./Data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./Data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./Data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./Data/MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your code\n",
    "__2. Run the next code cell to ensure the recently created MNIST dataset is available and to see an example of an image.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAAEGCAYAAABijql5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACT1JREFUeJzt3X+s1XUdx/HXGxCuXuReS/4IgxvBJRsrL2QQc85KG/3Y\nMmNt2l8OcirTmgNG+F+5alaWFpLZXH+kU5uFaNb6Q7NZgBR251KymQgsoYnAgNwV7+XTH9wWu/F9\nn/vr3HNf9zwf29kY7+/nnu8de/K522ffc6OUIgBeJjX6BgAMHeEChggXMES4gCHCBQwRLmCIcBsg\nIl6NiCsGeW2JiPnDfJ9hr8X4RrgYlojojIieiLi/0ffSjAgXw3W3pD81+iaaFeE2WEQsiYhtEXEk\nIvZHxMaImDrgsk9HxCsRcTAivhMRk05bvzIidkXE4Yj4bUR0jME9Xy3piKQn6/1eODPCbbw+SbdI\nOl/SMkmXS1o94JqrJF0sabGkKyWtlKSI+JykWyV9XtJMSc9IenAwbxoRm/r/szjT6/lk3QxJX5e0\nZgjfI0YZ4TZYKWVnKWV7KaW3lPKqpB9LumzAZbeXUg6VUvZKulPSNf1/f72kb5VSdpVSeiV9U1LX\nYHbdUsrqUkp7xeuDydLbJN1XStk31O8Vo2dKo2+g2UXEAknf06kd9Ryd+jfZOeCy0yPZI2lW/587\nJN0VEXec/iUlXdB/3Wjfa5ekKyQtGu2vjaFhx228H0n6m6TOUsoMnfrRNwZcM/u0P8+R9Fr/n/dJ\nun7Abnl2KWVrrTeNiHsi4njF64WKZR+V9B5JeyPigKS1klZExHOD/WYxOgi38c6VdFTS8Yi4UNKN\nZ7hmXUScFxGzJX1F0sP9f3+PpA0RsVCSIqItIr4wmDctpdxQSple8VpYsexeSfMkdfW/7pH0hKTl\ng/xeMUoIt/HWSvqipGOSfqL/RXm6LTr143O3ToVynySVUjZLul3SQxFxVNJfJX2qXjdaSnmzlHLg\nvy9JxyX1lFJer9d74syCB+kBP+y4gCHCBQwRLmCIcAFDhAsYIlzAEOEChggXMES4gCHCBQwRLmCI\ncAFDhAsYIlzAEOEChggXMDSkD4ubGtNKi1rrdS9A0+vRv3WivDXwM8f+z5DCbVGrlsblw78rAKln\ny+A+Y54flQFDhAsYIlzAEOEChggXMES4gCHCBQwRLmCIcAFDhAsYIlzAEOEChggXMES4gCHCBQwR\nLmCIcAFDhAsYIlzAEOEChggXMES4gCHCBQwRLmCIcAFDhAsYIlzAEOEChggXMES4gCHCBQwRLmCI\ncAFDhAsYIlzAEOEChqY0+gYwMpMXvi+d77q5LZ3v/uy96Xzp+hsrZ+0/25auRf2w4wKGCBcwRLiA\nIcIFDBEuYIhwAUOECxjiHHecm7xgXjpf/MCL6XzLzO503lcinR/rqJ63pytRT+y4gCHCBQwRLmCI\ncAFDhAsYIlzAEMdB48GSD1SOrr3/sXTpVa2HRvtuYIAdFzBEuIAhwgUMES5giHABQ4QLGCJcwBDn\nuGNgUktLOj/7uwcqZ7XOaf/+9ol0/syb89P5dW370nlPZ086R2Ow4wKGCBcwRLiAIcIFDBEuYIhw\nAUOECxjiHHcMHP7lu9P5Y/Merpzt7s3PUVfffEs6P9qR/xNft2FjOn/0sk2Vs6/OvyZd2/fy7nSO\n4WPHBQwRLmCIcAFDhAsYIlzAEOEChggXMMQ57iDUep621jnt9q5H0nn2qy5X3L0uXTvr8a35116x\nNJ1Pjvz/7oVnTa2clelnp2tRP+y4gCHCBQwRLmCIcAFDhAsYIlzAEOEChjjHHYQDqxan8x0X/TCd\nZ+e0ktT1/ZsqZxfcuSNdW9Kp1PqLZ9N53w9OpvOTyTv84+q2dO3c7nSMEWDHBQwRLmCIcAFDhAsY\nIlzAEOEChjgOklQu6Urnv17/7RpfIX+8rXPzjel8QXLkU3p7a7z3yNz+xvvT+bp3vlg565ta6zAK\n9cKOCxgiXMAQ4QKGCBcwRLiAIcIFDBEuYKhpznGnzO2onH3y3t+la8+fnJ/TfuKFFem886b80bpG\nnoY+9Er+yGJ2jovGYccFDBEuYIhwAUOECxgiXMAQ4QKGCBcw1DTnuC9947zK2aPtr6Rrd/f2pPPW\nVfkzs/V9orZxLlmWn/H+a4zuoxmx4wKGCBcwRLiAIcIFDBEuYIhwAUOECxiaMOe4Jy9dlM63X7qx\ncra/L38i9tr1a9P5ufu2p/PxrPXn+a/KnPTh6l8R+tM5T6drr3z6M+l875H2dJ6Z034knW/pfCKd\nd5/IT9dvnbtkyPc0lthxAUOECxgiXMAQ4QKGCBcwRLiAIcIFDE2Yc9zjs6el87ZJLZWzlvJ2urZr\nTXc6/83yD6Xz8eyGi59M5ydH8KnPmzt/Ney1kvTAsXdVzp47Xv052ZJ04e9XpvOW7nPS+SxtTeeN\nxo4LGCJcwBDhAoYIFzBEuIAhwgUMTZjjoLZdx9L5trcmV86W5SdJumvWH0c0n6TqR+OkkR25jFTt\nexu+Nfs/ks67b8sfxZz+h5crZ31vHErXvlf5EZ47dlzAEOEChggXMES4gCHCBQwRLmCIcAFDE+Yc\nt/zlhXT+tS+tqpyd3HAwXfvqvpnDuqfx4Pxnzkrn5/4zf6Tx2JePVs62LnowXfv48xel8wVbdqTz\nvnTa3NhxAUOECxgiXMAQ4QKGCBcwRLiAIcIFDE2Yc9xapjy1s3r4VL52gfaM7s0YOXiN70fPTmTs\nuIAhwgUMES5giHABQ4QLGCJcwBDhAoaa5hwXo6/WZzI/8rFN6fxWLRnN22kq7LiAIcIFDBEuYIhw\nAUOECxgiXMAQx0EYtkb+etBmx44LGCJcwBDhAoYIFzBEuIAhwgUMES5giHNc1M0dry2vccXhMbmP\niYgdFzBEuIAhwgUMES5giHABQ4QLGCJcwBDnuKibbS/NS+cL9OcxupOJhx0XMES4gCHCBQwRLmCI\ncAFDhAsYIlzAEOe4SM3onlY52/3xnnRty96po3076MeOCxgiXMAQ4QKGCBcwRLiAIcIFDBEuYChK\nGfzvOJ0R7yhL4/I63g7Q3J4tT+poORS1rmPHBQwRLmCIcAFDhAsYIlzAEOEChggXMES4gCHCBQwR\nLmCIcAFDhAsYIlzAEOEChggXMES4gCHCBQwRLmCIcAFDhAsYIlzAEOEChob08awR8bqkPfW7HaDp\ndZRSZta6aEjhAhgf+FEZMES4gCHCBQwRLmCIcAFDhAsYIlzAEOEChggXMPQf4ru6edb1Fh0AAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f01d0e50898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample , sample_label = mnist.train.next_batch(20)\n",
    "print_mnist(0, sample, sample_label)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create a Convolutional Neural Network Model.\n",
    "You need to first create the model architecture by defining the input layer, the convolutional layer(s), the fully connected layer, the dropout layer, and the final output layer along with any necessary transformation to pass the data between each of them.\n",
    "\n",
    "\n",
    "\n",
    "<img src='./Images/cnn.png' style=\"width:800px;\"></img>\n",
    "\n",
    "Remember that the described steps for building a CNN are a complement to the image above. After each one you will find the sample code you will need for the model. You must declare some parameters, so you will need to understand the code provided to you. To build a CNN, follow these steps:\n",
    "\n",
    "\n",
    "__1. Define data (x) and dropout probability (keep). These are created with [placeholders](https://www.tensorflow.org/api_docs/python/tf/placeholder). See below for a code example.__\n",
    "```python\n",
    "x = tf.placeholder(tf.float32, [None, 28 * 28]) # 28 x 28 inputs\n",
    "keep = tf.placeholder(tf.float32)\n",
    "```\n",
    "\n",
    "__2. Reshape the input to be a 2D matrix. The [reshape](https://www.tensorflow.org/api_docs/python/tf/reshape) module in TensorFlow creates this dimension.__\n",
    "\n",
    "**Note:** Specify the image width, height, and depth correctly.d:\n",
    "```python\n",
    "x_image = tf.reshape(x, [-1, IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_DEPTH])\n",
    "```\n",
    "\n",
    "__3. Add two convolutional layers. See below for a code example:__\n",
    "   1. Use the [convolution](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d) of the previous layer’s output with this layer’s weight as the activation signal. \n",
    "   2. Have [relu](https://www.tensorflow.org/api_docs/python/tf/nn/relu) as the activation function with the sum of the bias and activation signals as features.  \n",
    "   3. Perform [max pooling](https://www.tensorflow.org/api_docs/python/tf/nn/max_pool) on the activation function:\n",
    "```python\n",
    "W_conv1 = tf.Variable(tf.truncated_normal([KERNEL_WIDTH, KERNEL_HEIGHT, IN_DEPTH, OUT_DEPTH], stddev=0.1))\n",
    "b_conv1 = tf.Variable(tf.constant(0.1, shape=[OUT_DEPTH]))\n",
    "a_conv1 = tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "h_conv1 = tf.nn.relu(a_conv1 + b_conv1)\n",
    "h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, POOL_WIDTH, POOL_HEIGHT, 1],\n",
    "                        strides=[1, POOL_WIDTH, POOL_HEIGHT, 1], padding='SAME')\n",
    "```\n",
    "**Note:** The code shows that you will must create the weight and bias vectors for the\tlayer with [variable](https://www.tensorflow.org/api_docs/python/tf/Variable).\n",
    "\n",
    "__4. Reshape the convolutional layers output into a 1D vector. This creates the [reshaped](https://www.tensorflow.org/api_docs/python/tf/reshape) vector that will be used as input in the fully connected layer:__\n",
    "```python\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, CNN_NEURONS])\n",
    "```\n",
    "\n",
    "__5. Add a fully connected layer that will be structured with the weights and bias as [variable](https://www.tensorflow.org/api_docs/python/tf/Variable), and [relu](https://www.tensorflow.org/api_docs/python/tf/nn/relu) as the activation function with the sum of the [matrix multiplication](https://www.tensorflow.org/api_docs/python/tf/matmul) of the previous step’s output and this layer’s weight plus the bias as the features:__\n",
    "```python\n",
    "W_fc1 = tf.Variable(tf.truncated_normal([CNN_NEURONS, FULL_CONNECTED_NEURONS], stddev=0.1))\n",
    "b_fc1 = tf.Variable(tf.constant(0.1, shape=[FULL_CONNECTED_NEURONS]))\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "```\n",
    "\n",
    "__6. Add a dropout layer by using [dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) with the fully connected layer’s output, and the keep probability defined at the beginning as parameters:__\n",
    "```python\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep)\n",
    "```\n",
    "\n",
    "__7. Add a final output layer to classify the 10 possible different numbers with only the weight and bias as [variable](https://www.tensorflow.org/api_docs/python/tf/Variable) and the model’s output as the sum of [matrix multiplication](https://www.tensorflow.org/api_docs/python/tf/matmul)  of the previous layer’s output and this layer’s weight plus this layer’s bias:__\n",
    "```python\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([FULL_CONNECTED_NEURONS, OUT_NEURONS], stddev=0.1))\n",
    "b_fc2 = tf.Variable(tf.constant(0.1, shape=[OUT_NEURONS]))\n",
    "model = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foto = tf.placeholder(tf.float32, [None, 28 * 28]) # 28 x 28 inputs\n",
    "keep = tf.placeholder(tf.float32)\n",
    "foto_standar = tf.reshape(foto, [-1, 28, 28, 1])\n",
    "###############\n",
    "W_conv1 = tf.Variable(tf.truncated_normal([5 , 5, 1, 32], stddev=0.1))\n",
    "b_conv1 = tf.Variable(tf.constant(0.1, shape=[1]))\n",
    "a_conv1 = tf.nn.conv2d(foto_standar, W_conv1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "h_conv1 = tf.nn.relu(a_conv1 + b_conv1)\n",
    "h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 14, 14, 1],\n",
    "                  strides=[1, 14, 14, 1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_pool2_flat = tf.reshape(h_pool1, [-1, 196])\n",
    "W_fc1 = tf.Variable(tf.truncated_normal([196, 196], stddev=0.1))\n",
    "b_fc1 = tf.Variable(tf.constant(0.1, shape=[196]))\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_fc2 = tf.Variable(tf.truncated_normal([196, 10], stddev=0.1))\n",
    "b_fc2 = tf.Variable(tf.constant(0.1, shape=[10]))\n",
    "model = tf.matmul(h_fc1, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Code Cell \n",
    "Execute the following code cell to look at your model’s output. You should see a list of 10 elements with random numbers to be on track as your output. If you see another output, you have an error in your CNN structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 2560 values, but the requested shape requires a multiple of 196\n\t [[Node: Reshape_15 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](MaxPool_3, Reshape_15/shape)]]\n\nCaused by op 'Reshape_15', defined at:\n  File \"/opt/conda/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/conda/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/opt/conda/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-37-70f72fff150e>\", line 1, in <module>\n    h_pool2_flat = tf.reshape(h_pool1, [-1, 196])\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2448, in reshape\n    name=name)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 2560 values, but the requested shape requires a multiple of 196\n\t [[Node: Reshape_15 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](MaxPool_3, Reshape_15/shape)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 2560 values, but the requested shape requires a multiple of 196\n\t [[Node: Reshape_15 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](MaxPool_3, Reshape_15/shape)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-a0826b07be70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     out = sess.run(model,\n\u001b[1;32m      5\u001b[0m                    feed_dict = {foto: sample,\n\u001b[0;32m----> 6\u001b[0;31m                                 keep: 1})\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 2560 values, but the requested shape requires a multiple of 196\n\t [[Node: Reshape_15 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](MaxPool_3, Reshape_15/shape)]]\n\nCaused by op 'Reshape_15', defined at:\n  File \"/opt/conda/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/conda/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/opt/conda/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-37-70f72fff150e>\", line 1, in <module>\n    h_pool2_flat = tf.reshape(h_pool1, [-1, 196])\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2448, in reshape\n    name=name)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 2560 values, but the requested shape requires a multiple of 196\n\t [[Node: Reshape_15 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](MaxPool_3, Reshape_15/shape)]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    out = sess.run(model,\n",
    "                   feed_dict = {foto: sample,\n",
    "                                keep: 1})\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Accuracy\n",
    "To measure the accuracy during training, you will compare the model’s classification with the correct labels. Use the average of the classification error count as the measure for the whole model. To accomplish this refer to sample code on each step:\n",
    "\n",
    "\n",
    "__1. Create a [placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for the correct label. Refer to the sample code below:__\n",
    "```python\n",
    "label = tf.placeholder(tf.float32, [None, 10])   # 10 outputs\n",
    "```\n",
    "**Note:** There are only 10 outputs.\n",
    "\n",
    "\n",
    "__2. Compare the model result with the correct label and average the results to get the accuracy. Do this by running the following commands:__\n",
    "```python\n",
    "correct_prediction = tf.equal(tf.argmax(model, 1), tf.argmax(label, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "```\n",
    "\n",
    "__3. Evaluate the accuracy over test samples from a TensorFlow session by using the function `print_accuracy` below:__\n",
    "```python\n",
    "def print_accuracy(sess):\n",
    "    accuracy_sum = 0\n",
    "    for i in range(100):\n",
    "        x_, y_ = mnist.test.next_batch(100)\n",
    "        accuracy_sum += sess.run(accuracy,\n",
    "                                 feed_dict={x: x_,\n",
    "                                 label: y_,\n",
    "                                 keep: 1})\n",
    "    print(accuracy_sum/100)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Code Cell:\n",
    "Execute the following code cell to review your model’s accuracy. There should be one floating point value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print_accuracy(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Test \n",
    "The next task is to create the training graph for your model and train it. To accomplish this task, follow the steps and refer to their code samples.\n",
    "\n",
    "__1. Create a placeholder for the alpha value in the momentum method as shown below.__\n",
    "```python\n",
    "alpha = tf.placeholder(tf.float32)\n",
    "```\n",
    "\n",
    "__2. Create the training graph by adding the required steps to minimize cross-entropy using the [MomentumOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer).  To do this, refer to the following code sample:__\n",
    "```python\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=label, logits=model))\n",
    "train_graph = tf.train.MomentumOptimizer(learning_rate=LEARNING_RATE, momentum=alpha).minimize(cross_entropy)\n",
    "```\n",
    "\n",
    "__3. Train the model and print the accuracy of each epoch in a session by cycling through _epochS_ and _batches_ running the `train_graph` with data batches. Refer to the following code sample:__\n",
    "```python\n",
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for batch in range(550):\n",
    "        x_, y_ = mnist.train.next_batch(100)\n",
    "            \n",
    "        alpha_ = 0.5\n",
    "        if epoch > 5:\n",
    "            alpha_ = 0.9\n",
    "        if epoch > 8:\n",
    "            alpha_ = 0.99\n",
    "            \n",
    "        sess.run(train_graph,\n",
    "                     feed_dict={x: x_,\n",
    "                                label: y_,\n",
    "                                alpha: alpha_,\n",
    "                                keep: 0.5})\n",
    "    print_accuracy(sess)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Code Cell\n",
    "Execute the next code cell to print sample classification errors the final model made. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "to_print = 20\n",
    "cols = 4\n",
    "rows = to_print//cols\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(cols*3,rows*3))\n",
    "\n",
    "prints = 0\n",
    "done = False\n",
    "for batch in range(100):\n",
    "    x_, y_ = mnist.test.next_batch(100)\n",
    "    predictions = sess.run(YOUR_MODEL, feed_dict={x: x_,\n",
    "                                                      label: y_,\n",
    "                                                      keep: 1})\n",
    "    correct = sess.run(correct_prediction, feed_dict={x: x_,\n",
    "                                                         label: y_,\n",
    "                                                         keep: 1})\n",
    "    for i, is_correct in enumerate(correct):\n",
    "        if not is_correct:\n",
    "            print_mnist(i, x_, y_, predictions[i], \n",
    "                        axes[prints//cols, prints%cols])\n",
    "            prints += 1\n",
    "        if prints >= to_print:\n",
    "            done = True\n",
    "            break\n",
    "    if done:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "You created a functional Convolutional Neural Network to identify numbers from 0 to 9 that can be used in postal services or any other field. The number of inner layers, including their size, will have an impact on the model’s performance. Looking at the accuracy from each epoch you saw the effect of the gradient descent and possible drawbacks. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
